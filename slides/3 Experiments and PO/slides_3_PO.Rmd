---
title: "[ECON42720 Causal Inference and Policy Evaluation](https://benelsner82.github.io/causalinfUCD/)"
subtitle: "3 Potential Outcomes and Randomized Experiments"
author: "Ben Elsner (UCD)"
output:
  beamer_presentation:
    includes:
      in_header: "../Templates/template_metrics.tex"
classoption: "aspectratio=169, handout" 


--- 

```{r setup, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

library(cowplot)
library(ggplot2)
library(knitr)
library(kableExtra)

set.seed(1234)
graphdir <- "../../../causalinf_phd/Graphs/"

# generate graphs
# source("atttables.R")

```

## About this Lecture


## Lingo and Notation

The \brf{lingo of causal inference} is borrowed from \brf{medical trials}

- **treatment** is the intervention/variable whose effect we are interested in
- **treatment group** is the group of units that receives the treatment
- **control group** is the group of units that does not receive the treatment or receives a placebo
- **outcome** is the variable that is potentially affected by the treatment

\vfill
\brf{We are after the causal effect}: \brf{treatment} ($D$) $\rightarrow$ \brf{outcome} ($Y$)




## Resources


\brf{This lecture is based on}

- \citet{cunningham_2018}, Chapter 4
- \citet{angrist_2009}, Chapter 2 

\vfill

Find more about the course on the [\brf{course page}](https://benelsner82.github.io/causalinfUCD/)

## Notation


## Causality

A common challenge in applied econometrics is to **separate a causal effect** from the **influence of third factors**
\vfill

```{r, out.width = '60%', echo=FALSE, fig.align="center"}
p1 <- ggdraw() + draw_image(paste0(graphdir, "dag_selection.PNG"), scale = 0.9)
p2 <- ggdraw() + draw_image(paste0(graphdir, "dag_selection2.PNG"), scale = 0.9)

plot_grid(p1, p2)
```
\vfill
We often have a \brf{good (theoretical) idea} why $D \rightarrow Y$ 

- but \brf{$X$ is a confounding factor}
- often the problem: we also have an idea what $X$ could be...
- but \brf{cannot observe it} (notation: $u$ for ``unobservable'')






## Causality
```{r, out.width = '35%', echo=FALSE, fig.align="center"}
knitr::include_graphics(paste0(graphdir, "dag_selection2.png"))
```
Common challenge: \brf{selection into treatment}
\vfill
In microeconomics we learn

- **people** make \brf{rational choices}...
- ...as do **firms**
- ...as do **governments**

\vfill
Problem: we do **not observe all the determinants** of these choices (i.e. $u$)



## Causality
Examples for \brf{selection into treatment}: 
\vfill
\brf{Going to the gym makes you healthier}

- good reason to believe so
- but people who go to the gym are different from those who don't
- observed correlation $\neq$ causation

\pause
\vfill
\brf{Exporting boosts firm profitability}

- good reason to believe so
- but exporters are different in many ways from non-exporters
- observed correlation $\neq$ causation





## Causality
Problem: it is \brf{not easy to account for all confounding factors} 

- because we know what they are but can't observe them
- or because we don't know what they are (e.g. ``common shocks'')

\vfill
The \brf{burden of proof is on the researcher}

- If you make a causal statement, you need to make a convincing case
- but causality cannot be proven without assumptions...
- ...and these assumptions need to be believed





## The Potential Outcomes Framework
We will now focus on \brf{binary treatments}
\vfill
Some **notation from experimental studies**


- $i$ is an index for the units in the population under study.

\vfill

-  $D_{i}$ is the \brf{treatment status}:

- $D_{i} = 1$ if unit $i$ has been exposed to treatment,
-  $D_{i} = 0$ if unit $i$ has not been exposed to treatment.


\vfill

- $Y_{i}(D_{i})$ indicates the \brf{potential outcome according to treatment}:

-  $Y_{i}(1)\equiv Y_{i1}$ is the outcome in case of treatment,
- $Y_{i}(0)\equiv Y_{i0}$ is the outcome in case of no treatment.







## The Potential Outcomes Framework \citep{rubin1974}
The \brf{observed outcome} is then

\begin{equation*}
Y_{i}  = 
\left\{\begin{array}{lc}
Y_{i1} & \textrm{if } D_{i}=1  \\
Y_{i0} & \textrm{if } D_{i}=0
\end{array} \right.
\end{equation*}
\vfill
\begin{equation*}
 =  D_{i}Y_{i1} + (1 - D_{i})Y_{i0} 
\end{equation*}
\vfill
\begin{equation*}
 = Y_{i0} + \underbrace{(Y_{i1} - Y_{i0})}_{\mbox{treatment effect}}D_{i}
\end{equation*}
\vfill
We are interested in the (individual) \brf{treatment effect} \(\Delta_{i} = Y_{i1} - Y_{i0}\).






## The Fundamental Problem of Causal Inference
 \brf{We cannot identify} the individual treatment effect \(\Delta_{i} = Y_{i1} - Y_{i0}\)
 \vfill
 This is \brf{logically impossible}

- we either observe that a unit was treated or not
- but never both treatment statuses at the same time






## The Fundamental Problem of Causal Inference
A \brf{critical ingredient} to establish causality: the \brf{counterfactual}
\vfill
\brf{What would have happened} to a unit if 

- the treatment status $D \in \{0,1\}$ was different?
- the treatment intensity was different?

\vfill
The \brf{counterfactual} is entirely \brf{hypothetical}, but we cannot make causal claims without it!

\vfill
\pause
\brf{Statistical solution}: **Average Treatment Effect** (**ATE**) for a random unit
\begin{equation*}
E(\Delta_{i}) = E(Y_{i1} - Y_{i0}) = E(Y_{i1}) - E(Y_{i0})
\end{equation*}
\vfill

If a **random unit was treated**, the **expected difference in their outcome** is the ATE




## The Fundamental Problem of Causal Inference
To see how the \brf{ATE can(not) be estimated from observational data}, it is useful to consider a \brf{hypothetical effect}
\vfill
The \brf{Average Treatment Effect on the Treated} (**ATT**)
\begin{equation*}
\begin{array}{ll}
ATT = E(\Delta_{i}|D_{i} = 1) & = E(Y_{i1} - Y_{i0}|D_{i} = 1)\\
& = E(Y_{i1}|D_{i} = 1) - E(Y_{i0}|D_{i} = 1).\\
\end{array}
\end{equation*}
\vfill
**Interpretation**: Average difference in potential outcomes for those who were treated


## The Average Treatment Effect on the Untreated (ATU)

Similarly, we can define the \brf{Average Treatment Effect on the Untreated} (**ATU**) as: 


\begin{equation*}
\begin{array}{ll}
ATU = E(\Delta_{i}|D_{i} = 0) & = E(Y_{i1} - Y_{i0}|D_{i} = 0)\\
& = E(Y_{i1}|D_{i} = 0) - E(Y_{i0}|D_{i} = 0).\\
\end{array}
\end{equation*}

\vfill
**Interpretation**: the **average difference in potential outcomes** for those who were **not treated**



 

## Treatment Effects

\begin{tabular}{ccccc}
\hline
\textbf{Person} & \textbf{D} & \textbf{PO Treated} $Y^1$ & \textbf{PO Untreated} $Y^0$  & \textbf{Causal Effect} \\
\hline
1 & 1 & 80 & 60 & 20 \\
2 & 1 & 75 & 70 & 5 \\
3 & 0 & 70 & 60 & 10 \\
4 & 1 & 85 & 80 & 5 \\
5 & 0 & 75 & 70 & 5 \\
6 & 0 & 80 & 80 & 0 \\
7 & 0 & 90 & 100 & -10 \\
8 & 1 & 85 & 80 & 5 \\
\hline
\end{tabular}

\vfill
Here we observe the \brf{potential outcomes} for each person. Some people are treated ($D=1$), some are not ($D=0$). 

## The Average Treatment Effect 

\begin{tabular}{ccccc}
\hline
\textbf{Person} & \textbf{D} & \textbf{PO Treated} $Y^1$ & \textbf{PO Untreated} $Y^0$  & \textbf{Causal Effect} \\
\hline
1 & 1 & 80 & 60 & \cellcolor{green!25} 20 \\
2 & 1 & 75 & 70 & \cellcolor{green!25} 5 \\
3 & 0 & 70 & 60 & \cellcolor{green!25}10 \\
4 & 1 & 85 & 80 & \cellcolor{green!25}5 \\
5 & 0 & 75 & 70 & \cellcolor{green!25}5 \\
6 & 0 & 80 & 80 & \cellcolor{green!25}0 \\
7 & 0 & 90 & 100 & \cellcolor{green!25}-10 \\
8 & 1 & 85 & 80 & \cellcolor{green!25}5 \\
\hline
\end{tabular}

\vfill
The ATE is the average of the last column: $5$


## The Average Treatment Effect on the Treated (ATT)

\begin{tabular}{ccccc}
\hline
\textbf{Person} & \textbf{D} & \textbf{PO Treated} $Y^1$ & \textbf{PO Untreated} $Y^0$  & \textbf{Causal Effect} \\
\hline
1 & 1 & 80 & 60 & \cellcolor{green!25}  20 \\
2 & 1 & 75 & 70 & \cellcolor{green!25}  5 \\
3 & 0 & 70 & 60 & 10 \\
4 & 1 & 85 & 80 & \cellcolor{green!25} 5 \\
5 & 0 & 75 & 70 & 5 \\
6 & 0 & 80 & 80 & 0 \\
7 & 0 & 90 & 100 & -10 \\
8 & 1 & 85 & 80 & \cellcolor{green!25} 5 \\
\hline
\end{tabular}

\vfill
The ATT is the average of the green cells: $8.75$



## The Average Treatment Effect on the Untreated (ATU)

\begin{tabular}{ccccc}
\hline
\textbf{Person} & \textbf{D} & \textbf{PO Treated} $Y^1$ & \textbf{PO Untreated} $Y^0$  & \textbf{Causal Effect} \\
\hline
1 & 1 & 80 & 60 & 20 \\
2 & 1 & 75 & 70 & 5 \\
3 & 0 & 70 & 60 & \cellcolor{green!25} 10 \\
4 & 1 & 85 & 80 & 5 \\
5 & 0 & 75 & 70 & \cellcolor{green!25} 5 \\
6 & 0 & 80 & 80 & \cellcolor{green!25} 0 \\
7 & 0 & 90 & 100 & \cellcolor{green!25} -10 \\
8 & 1 & 85 & 80 & 5 \\
\hline
\end{tabular}

\vfill
The ATU is the average of the white cells: $1.25$

\vfill
Here we have $ATT>ATE>ATU$, which may indicate **selection into treatment**: those who benefit most from the treatment are most likely to take it





## ATE/ATT/ATU: Which Parameter is most Relevant?

There is \brf{no clear answer to this question}

\vfill

\brf{ATE is the most general parameter}

- what if we give the average person/firm/unit a treatment
- This is interesting for medical trials and for many policy questions

\vfill

\brf{ATT is often interesting for policy evaluation}

- take those who took up the policy
- what would have happened to them if they had not taken up the policy

\vfill

\brf{ATU is sometimes interesting for policy evaluation}

- We may be concerned about the people who did not take up the policy
- How would they be affected if they took up the policy

\vfill
But: We \brf{need all three to interpret the estimation results}






## Comparison by Treatment Status
In many applications, we want to \brf{estimate the ATE or the ATT}
\vfill
But we \brf{only observe}

- Whether a unit was treated or not
- The actual outcome of the unit

\vfill
Solution (?): \brf{comparison of means/simple difference in outcomes}, which can be estimated from two samples of data (treatment and control group)
\begin{equation*}
\begin{array}{ll}
SDO &= E(Y_i |D_i=1)-E(Y_i |D_i=0) \\
&= \frac{1}{N_T}\displaystyle\sum_i (y_i \mid d_i=1) - \frac{1}{N_C}\displaystyle\sum_i (y_i \mid d_i=0)   \\
\end{array}
\end{equation*}



## Simple Difference in Outcomes (SDO)


\begin{tabular}{ccccc}
\hline
\textbf{Person} & \textbf{D} & \textbf{PO Treated} $Y^1$ & \textbf{PO Untreated} $Y^0$  & \textbf{Causal Effect} \\
\hline
1 & 1 & \cellcolor{green!25}80 & 60 & 20 \\
2 & 1 & \cellcolor{green!25}75 & 70 & 5 \\
3 & 0 & 70 & \cellcolor{red!25}60 & 10 \\
4 & 1 & \cellcolor{green!25}85 & 80 & 5 \\
5 & 0 & 75 & \cellcolor{red!25}70 & 5 \\
6 & 0 & 80 & \cellcolor{red!25}80 & 0 \\
7 & 0 & 90 & \cellcolor{red!25}100 & -10 \\
8 & 1 & \cellcolor{green!25}85 & 80 & 5 \\
\hline
\end{tabular}

\vfill
We compare here the \textcolor{green}{observed outcomes of the treated} to the \textcolor{red}{observed outcomes of the untreated}

\vfill

$SDO=\textcolor{green}{81.25} - \textcolor{red}{77.5}=3.75$

## Comparison by Treatment Status
Problem with SDO: \brf{treated and untreated units are not comparable}

\begin{equation}\nonumber
\begin{array}{rcl}
E(Y_{i}|D_{i} = 1) &-& E(Y_{i}|D_{i} = 0)\\
 &=& E(Y_{i1}|D_{i} = 1) - E(Y_{i0}|D_{i} = 0)\\
 &=& \underbrace{E(Y_{i1}|D_{i} = 1) - \textcolor{brickred}{E(Y_{i0}|D_{i} = 1)}}_{ATT} + \underbrace{\textcolor{brickred}{E(Y_{i0}|D_{i} = 1)} - E(Y_{i0}|D_{i} = 0)}_{\text{Selection bias}}\\
\end{array}
\end{equation}
\vfill

\brf{Selection bias}: the potential outcomes would differ even if both groups were untreated


\vfill
\small
Note how we add and subtract $E(Y_{i0}|D_{i} = 1)$ here
\normalsize


## Now Suppose We Want to Estimate the ATE

Note that we can write the ATE as: $ATE=\pi ATT + (1-\pi)ATU$

\vfill
The \brf{simple difference in outcomes yields}: 

\begin{equation}\nonumber
\begin{array}{rcl}
E(Y_{i}|D_{i} = 1) - E(Y_{i}|D_{i} = 0) &=&\\
 &=& ATE  \\
 &+& \underbrace{\textcolor{brickred}{E(Y_{i0}|D_{i} = 1)} - E(Y_{i0}|D_{i} = 0)}_{\text{Selection bias}}\\
 &+& \underbrace{(1-\pi)\left[ATT-ATU\right]}_{\text{HTE Bias}}\\
\end{array}
\end{equation}

Our estimate of the \brf{ATE is contaminated by two biases}:

- **selection bias**
- **heterogeneous treatment effects** 


## Selection Bias

\begin{tabular}{ccccc}
\hline
\textbf{Person} & \textbf{D} & \textbf{PO Treated} $Y^1$ & \textbf{PO Untreated} $Y^0$  & \textbf{Causal Effect} \\
\hline
1 & 1 & 80 & \cellcolor{green!25}60 & 20 \\
2 & 1 & 75 & \cellcolor{green!25}70 & 5 \\
3 & 0 & 70 & \cellcolor{red!25}60 & 10 \\
4 & 1 & 85 & \cellcolor{green!25}80 & 5 \\
5 & 0 & 75 & \cellcolor{red!25}70 & 5 \\
6 & 0 & 80 & \cellcolor{red!25}80 & 0 \\
7 & 0 & 90 & \cellcolor{red!25}100 & -10 \\
8 & 1 & 85 & \cellcolor{green!25}80 & 5 \\
\hline
\end{tabular}

\vfill
The \brf{selection bias} is the difference between the green and red cells. 

\vfill

In this case, $E(Y_{i0}|D_{i} = 1) - E(Y_{i0}|D_{i} = 0) = 72.5-77.5=-5$

\vfill
So in absence of the treatment, the untreated have more favourable outcomes than the treated


## Selection Bias

The \brf{selection bias} is $E(Y_{i0}|D_{i} = 1) - E(Y_{i0}|D_{i} = 0)$

\vfill
This means that, even \brf{without the treatment}, the \brf{two groups would have different outcomes}

\vfill
Selection bias is very common! Whenever there is a \brf{confounder, we have selection bias}


## Heterogeneous Treatment Effects

$\text{HTE bias}=(1-\pi)\left[ATT-ATU\right]$

\vfill

Another problem is that the \brf{treatment effect may vary across units}

- People who take the treatment may be different from those who do not
- People with **stronger treatment effects** may be **more likely** to take the treatment

\vfill

\brf{Heterogeneous treatment effects bias} can even occur in a randomised experiment

- We can **hardly ever enforce that people take the treatment**
- Unlike in physics or chemistry, in the social sciences we can only **encourage people to take the treatment**
- We speak here of \brf{imperfect compliance}




## Heterogeneous Treatment Effects Bias

\begin{tabular}{ccccc}
\hline
\textbf{Person} & \textbf{D} & \textbf{PO Treated} $Y^1$ & \textbf{PO Untreated} $Y^0$  & \textbf{Causal Effect} \\
\hline
1 & 1 & 80 & 60 & \cellcolor{green!25}20 \\
2 & 1 & 75 & 70 & \cellcolor{green!25}5 \\
3 & 0 & 70 & 60 & \cellcolor{red!25}10 \\
4 & 1 & 85 & 80 & \cellcolor{green!25}5 \\
5 & 0 & 75 & 70 & \cellcolor{red!25}5 \\
6 & 0 & 80 & 80 & \cellcolor{red!25}0 \\
7 & 0 & 90 & 100 & \cellcolor{red!25}-10 \\
8 & 1 & 85 & 80 & \cellcolor{green!25}5 \\
\hline
\end{tabular}

\vfill
The \brf{heterogeneous treatment effects bias} is the difference between the green and red cells weighted by the \brf{probability of treatment}

\vfill

$\text{HTE bias}=(1-\pi)\left[\textcolor{green}{ATT}-\textcolor{red}{ATU}\right]=0.5\times \left[ \textcolor{green}{8.75}-\textcolor{red}{1.25}\right]=3.75$



## SDO vs. ATT

In our example, $SDO=3.75$

\vfill
\begin{equation*}
\begin{array}{rcl}
SDO &=& ATT + \text{Selection Bias} \\
    &=& 8.75 - 5 = 3.75
\end{array}
\end{equation*}

\vfill
In our case, the \brf{SDO under-estimates the ATT} by 5 because of selection bias. Without the treatment, treated units have less favourable outcomes than untreated units. 


## SDO vs ATE

\begin{equation*}
\begin{array}{rclllll}
SDO &=& ATE &+& \text{Selection Bias} &+& \text{HTE Bias} \\
    &=& 5 &-& 5 &+& 3.75 \\
    &=& 3.75
\end{array}
\end{equation*}

\vfill

In our case, the SDO also under-estimates the ATE. This is the result of two biases going in opposite directions. The overall bias is negative. 


## Putting it all together

The **previous slides** have shown that 

- a \brf{simple (a.k.a. naive) comparison of treated and untreated} units yields a \brf{biased estimate} of the ATE and ATT
- It is \brf{not random} whether a unit is treated or not or \brf{chooses to get treated or not}
- This choice leads to \brf{selection bias} and \brf{heterogeneous treatment effects bias}
- A \brf{randomised experiment} can **eliminate selection bias** but **not necessarily the HTE bias**


## Implication for research practice:

We need to **understand the sources of bias** in our context

\vfill
We **cannot test directly for the presence of bias** 

- no matter how much big data enthusiasts make us believe that we can

\vfill

We need to be humble about **what parameters we can identify with our data**
- Example: ATT does not suffer from HTE bias, but is it relevant?






## Comparison by Treatment Status
But in most cases, \brf{we run regressions} rather than comparing means
\begin{equation}\nonumber
\begin{array}{lcccccc}
Y_{i} =& \alpha &+& \beta & D_{i} & + & \varepsilon_{i}\\
    & = & & = & & & =\\
    & E(Y_{i0}) & & (Y_{i1}-Y_{i0})& &&Y_{i0}-E(Y_{i0})\\
\end{array}
\end{equation}
\vfill
Take expectations conditional on \(D_{i}\):
\begin{equation}\nonumber
\begin{array}{rl}
E(Y_{i}|D_{i} = 1) =& \alpha + \beta +  E(\varepsilon_{i}|D_{i} = 1)\\
E(Y_{i}|D_{i} = 0) = & \alpha + E(\varepsilon_{i}|D_{i} = 0)\\
\end{array}
\end{equation}




## Comparison by Treatment Status
The OLS estimate of \(\beta\) is
\begin{equation*}\label{eq5}
\begin{array}{rcl}
E(Y_{i}|D_{i} = 1) &-& E(Y_{i}|D_{i} = 0)\\
& = & \underbrace{\beta}_{\mbox{treatment effect}}  +  \underbrace{E(\varepsilon_{i}|D_{i} = 1) - E(\varepsilon_{i}|D_{i} = 0)}_{\mbox{selection bias}}.
\end{array}
\end{equation*}




## Comparison by Treatment Status
\brf{Selection bias in theory} $E(Y_{i0}|D_{i} = 1) - E(Y_{i0}|D_{i} = 0)=E(\varepsilon_{i}|D_{i} = 1) - E(\varepsilon_{i}|D_{i} = 0)$

- Treated and untreated units don't have the same potential outcomes

\vfill
\brf{In practice, put simply}: **treated and untreated units are different**
\vfill
\pause
\brf{Selection bias is pervasive} because **people choose what's best** for them

- There is simply no reason to believe the bias is zero
- Causal inference provides techniques to eliminate selection bias under assumptions









## Randomized Experiments
\brf{Experiments} provide a \brf{clean way to eliminate selection bias}
\vfill
Even if in most cases it is **not possible to run experiments**, a **clean experiment** serves as the **benchmark** for all the methods in this course
\vfill
\brf{Idea}: the closer we get to the **ideal experimental setting**, the closer we get to estimating a **causal effect**






## Randomized Experiments
\brf{Basic idea}: \brf{randomly assign treatment} across units
\vfill
\brf{Two conditions} have to be fulfilled: 

- **assignment** to treatment and control group is **random**
- there is **full compliance** with the treatment (plus: no attrition)

\vfill
In that case, the **treatment and control group** are **statistically identical**





## Randomized Experiments
\brf{Formally} (T: treatment group, C: control group)
\begin{equation*}\label{eq7}
E\{Y_{i0}|i \in C\} = E\{Y_{i0}|i \in T\}
\end{equation*}
and
\begin{equation*}\label{eq8}
E\{Y_{i1}|i \in C\} = E\{Y_{i1}|i \in T\}.
\end{equation*}

- ...both groups have the \brf{same potential outcomes} in expectation





## Randomized Experiments
Therefore, we can obtain an \brf{unbiased and consistent estimate of the ATE}
\vfill
\begin{equation*}\label{eq9}
E(\Delta _{i}) = E(Y_{i1} - Y_{i0}) = E\{Y_{i1}|i \in T\} - E\{Y_{i0}|i \in C\}.
\end{equation*}
\vfill
$\Rightarrow$ **comparison of means** is meaningful (causal effect in expectation)
\vfill
$\Rightarrow$ Randomization solves the \brf{fundamental problem of causal inference}




## Randomized Experiments
But \brf{what if not everyone complies} with the treatment?
\vfill
Examples

- Not every job seeker who is offered training takes part
- Not every person eligible for a medical card/social benefits/etc applies

\vfill
\begin{equation*}
E\{Y_{i1}|i \in T\} - E\{Y_{i0}|i \in C\} \neq ATE
\end{equation*}
\vfill
\pause
As we will learn later in the course, **all is not lost**

- The resulting **treatment effect can still be meaningful**
- ...as long as **treatment is random**





## Randomized Experiments
An **important assumption** underlying causal inference in experiments
\vfill
\begin{center}
\brf{SUTVA}: \brf{S}table \brf{U}nit \brf{T}reatment \brf{V}alue \brf{A}ssumption
\end{center}
\vfill
In \brf{plain English}

- treatment of one unit must not affect the potential outcomes of another
- i.e. no spillovers, general equilibrium effects, etc




## Randomized Experiments
\brf{SUTVA} is an \brf{untestable assumption}
\vfill
Examples for \brf{violations}: 

- information leaks from treatment to control group
- large-scale job training programs $\Rightarrow$ GE effects
- health interventions (capacity constraints in medical facilities)

\vfill
\brf{Implications:} 

- One reason why small interventions don't scale up
- Important to choose the right control group





## Cookbook for Analyzing a Randomized Experiment
**1) Explain experimental design** in detail, in particular

- How was the randomization carried out
- Discuss compliance (or likely non-compliance)
- Argue why SUTVA holds

\vfill
\pause
**2) Show balancing tests** based on **pre-treatment characteristics**

- Do treatment and control group differ before the experiment?

- Use pre-treatment outcomes if possible
- Use other pre-treatment characteristics that may predict selection into treatment

- If you use regression analysis in the paper, regress the pre-treatment x on the treatment
- Never use post-treatment outcomes (NEVER EVER!)

\begin{equation*}
x_i=\delta_1 + \delta_2 D_i + \eta_i
\end{equation*}






## Cookbook for Analyzing a Randomized Experiment
**3) Show and discuss results**

- **Compare means** across treatment and control groups
- Add **pre-treatment characteristics $X_i$** as controls


\begin{equation*}
y_i=\alpha + \beta D_i + \boldsymbol{X_i\gamma} + u_i
\end{equation*}

\vfill
\brf{Why add controls?}
\pause

- Additional test if randomization worked ($\beta$ should not change)
- Estimates become more precise (less noise in the model $\Rightarrow$ lower SE)






## Example: Tennessee STAR Experiment
\brf{Research Question}: **does class size matter** to student learning? **\citep{krueger_1999}**
\vfill
Implemented on cohort of kindergartners (i.e. senior infants) in
1985/86 in Tennessee.
\vfill
Lasted 4 years, then everyone went back to regular size class.
\vfill
\pause

**Three treatments**

1. Small class 13-17
2. Regular class 22-25
3. Regular class with Aide





## Example: Tennessee STAR Experiment
Schools had to have **at least 3 classes** to participate.
\vfill
Entering cohort **randomly assigned to class type**. Teachers also randomly assigned.
\vfill
I.e. randomization was carried out **within schools**
\vfill
Test scores measured towards **end of each school year** in March.




## Example: Tennessee STAR Experiment
\brf{Balancing tests}: do treatment and control groups have the **same pre-treatment characteristics?**

```{r, out.width = '45%', echo=FALSE, fig.align="center"}
knitr::include_graphics(paste0(graphdir, "star1.pdf"))
```


- They are similar in age, race and SES
- Attrition rates are similar
- Treatment and outcomes differ





## Example: Tennessee STAR Experiment

\citet{krueger_1999} uses a \brf{regression to analyse the experiment}
\vfill
The \brf{most comprehensive specification} includes **pre-treatment characteristics** and **school fixed effects**
\begin{equation*}
y_{is}=\alpha + \beta D_{is} + \boldsymbol{X_{is}'\gamma} + \delta_s + u_{is}
\end{equation*}
\vfill
\brf{Why include fixed effects?}
\pause

- **Randomization** was carried out **within schools**
- Children in different school types may **react differently to the treatment**
- The FE estimator compares children within the same school






## Example: Tennessee STAR Experiment

```{r, out.width = '65%', echo=FALSE, fig.align="center"}
knitr::include_graphics(paste0(graphdir, "star2.pdf"))
```





## Example: Tennessee STAR Experiment
Result: \brf{smaller classes are more effective}
\vfill
\brf{Experimental design appears valid}

- Balancing tables point to clean randomization
- Estimates not affected by controls for pre-treatment characteristics

\vfill
The **same cookbook approach** can be used for **non-experimental studies**



## Discrete vs. continuous treatment
So far, we discussed experiments with a \brf{discrete treatment}
\vfill 
The \brf{same assumptions apply} to experiments with a \brf{continuous treatment}

- The **treatment intensity varies** across units
- treatment intensity is **randomly assigned**

\vfill
Possibilites for researchers:

- **Discretize** and compare mean outcomes (e.g. above/below median)
- Estimate **marginal effect in a regression**




## Randomized Experiments as Templates
\brf{Randomized experiments are often difficult or impossible} to conduct
\vfill
But they serve as a **template for estimating causal effects** in non-experimental settings
\vfill
Any study that **claims to estimate a causal effect** should

- explain what the treatment is
- and under what conditions the assignment of the treatment (intensity) is as good as random
- ...even if the world is not perfect, there is no harm thinking about the perfect

\vfill
\pause
\brf{My advice} (after 100+ referee reports, several published papers and many rejections): **ignore the experimental template at your own peril**





## .
\tiny
\bibliographystyle{authordate1}
\bibliography{../../../causalinf_phd/bibliography_causalinf}

## Appendix


## Group Work I

ATE, ATT, ATU


## Group Work II

## Derivation of SDO Decomposition

\begin{align*}
E(Y^1\mid D=1) &- E(Y^0\mid D=0) \\ 
&= E(Y^1\mid D=1)-E(Y^1\mid D=0) + E(Y^1\mid D=0)-E(Y^0\mid D=0)\\
&= \underbrace{E(Y^1\mid D=1)-E(Y^1\mid D=0)}_{\text{ATT}} + \underbrace{E(Y^1\mid D=0)-E(Y^0\mid D=0)}_{\text{Selection Bias}}\\ 
\end{align*}

## Derivation of SDO Decomposition

Now consider $ATE=\pi ATT + (1-\pi)ATU$

\begin{align*}
ATE &= \pi ATT + (1-\pi)ATU \\
&= \pi ATT + ATT - ATT + (1-\pi)ATU \\
\end{align*}

Re-arranging yields

\begin{align*}
ATT &= ATE + (1-\pi)ATT - (1-\pi)ATU \\
&= ATE + (1-\pi)[ATT-ATU]\\
\end{align*}

## Derivation of SDO Decomposition

We can plug this into the SDO decomposition and get


\begin{align*}
E(Y^1\mid D=1) &- E(Y^0\mid D=0) \\ 
&= ATE \\
&+ \underbrace{E(Y^1\mid D=0)-E(Y^0\mid D=0)}_{\text{Selection Bias}}\\ 
&+ \underbrace{(1-\pi)[ATT-ATU]}_{\text{HTE Bias}}\\
\end{align*}




## .


```{r child = '../Templates/socialmedia.Rmd'}
```


## Contact

```{r child = '../Templates/contactpage.Rmd'}
```


